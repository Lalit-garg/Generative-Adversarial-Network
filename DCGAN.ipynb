{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MMTR10ZaMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "91985bfa-f30d-4503-a640-85786b2cee30"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential,Model\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import adam\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2wLEKNyaWMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "597d9cf9-c1af-4ca8-ec29-70479b386bd6"
      },
      "source": [
        "# Load Mnist Data\n",
        "(X_train,_),(_,_)=mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X2pXV1Da8vR",
        "colab_type": "code",
        "outputId": "f28b6fde-ef6d-494d-fb7a-c4266d02b133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Shape of our data \n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7aKjjkca-PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape data from 60000*28*28 to 60000*28*28*1\n",
        "X_train=X_train.reshape((*X_train.shape,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miHU2sK7bMev",
        "colab_type": "code",
        "outputId": "d897c8ad-0ebf-4a48-9836-46dca4809c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Final Shape\n",
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D-GdmLgbQ-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define batch size\n",
        "BATCH_SIZE=256\n",
        "NO_OF_BATCHES=int(60000/256)\n",
        "# Define dimension of initial Fake Data \n",
        "NOISE_DIM=100\n",
        "TOTAL_EPOCHS=50\n",
        "HALF_BATCH=128\n",
        "# Define loss\n",
        "adam=adam(lr=2e-4,beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWgnjOkBbr2G",
        "colab_type": "code",
        "outputId": "a1398149-81f2-4922-f51d-cb7711c517a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "# Generator\n",
        "generator=Sequential()\n",
        "\n",
        "generator.add(Dense(7*7*128,input_shape=(NOISE_DIM,)))\n",
        "generator.add(Reshape((7,7,128)))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "\n",
        "generator.add(Conv2DTranspose(64,kernel_size=(5,5),strides=(2,2),padding=\"same\"))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "\n",
        "generator.add(Conv2DTranspose(1,kernel_size=(5,5),strides=(2,2),padding=\"same\",activation=\"tanh\"))\n",
        "generator.compile(loss=\"binary_crossentropy\",optimizer=adam)\n",
        "generator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 839,937\n",
            "Trainable params: 839,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSFufzRIbtLm",
        "colab_type": "code",
        "outputId": "599430cd-acc8-4cb6-8679-0934f37759bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# Discriminator\n",
        "discriminator=Sequential()\n",
        "discriminator.add(Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=(28,28,1)))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Conv2D(64,(5,5),strides=(2,2),padding='same'))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1,activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "discriminator.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          102464    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 3137      \n",
            "=================================================================\n",
            "Total params: 107,265\n",
            "Trainable params: 107,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8i-SqnKjx2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable=False\n",
        "gan_input=Input(shape=(NOISE_DIM,))\n",
        "generated_image=generator(gan_input)\n",
        "gan_output=discriminator(generated_image)\n",
        "\n",
        "#Functional API\n",
        "model=Model(gan_input,gan_output)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=adam)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX0tvBcCdvqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to save final generated images\n",
        "!mkdir images model\n",
        "def save_imgs(epoch,samples=100):\n",
        "\n",
        "  noise=np.random.normal(0,1,size=(samples,NOISE_DIM))\n",
        "  generated_img=generator.predict(noise)\n",
        "  generated_imgs=generated_img.reshape(samples,28,28)\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(samples):\n",
        "    plt.subplot(10,10,i+1)\n",
        "    plt.imshow(generated_imgs[i],interpolation=\"nearest\",cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.savefig(\"images/gan_output_epoch_{0}.png\".format(epoch+1))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liR4toFCeD6c",
        "colab_type": "code",
        "outputId": "4fce7c4c-21d2-4afc-9d75-13020926278e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Training Loop\n",
        "for epoch in range(50):\n",
        "  epoch_d_loss=0\n",
        "  epoch_g_loss=0\n",
        "\n",
        "  #Mini Batch SGD\n",
        "  for step in range(NO_OF_BATCHES):\n",
        "    #Step1-Train Discriminator\n",
        "    #50% Real Data +50% of fake data\n",
        "    #idx=np.random.randint(low,high,no_of_numbers)\n",
        "    idx=np.random.randint(0,X_train.shape[0],HALF_BATCH)\n",
        "    real_imgs=X_train[idx]\n",
        "\n",
        "\n",
        "    #FAKE data\n",
        "    noise=np.random.normal(0,1,size=(HALF_BATCH,NOISE_DIM))\n",
        "    fake_imgs=generator.predict(noise) #Forward\n",
        "\n",
        "    #Lables\n",
        "    real_y=np.ones((HALF_BATCH,1))*0.9 # One sided label smoothing for discriminator\n",
        "    fake_y=np.zeros((HALF_BATCH,1))\n",
        "\n",
        "    #Train our Discriminator\n",
        "    d_loss_real=discriminator.train_on_batch(real_imgs,real_y)\n",
        "    d_loss_fake=discriminator.train_on_batch(fake_imgs,fake_y)\n",
        "    d_loss=0.5*d_loss_real + 0.5*d_loss_fake\n",
        "\n",
        "    epoch_d_loss+=d_loss\n",
        "\n",
        "    #Train Generator (Considering Frozen Discriminator)\n",
        "    noise=np.random.normal(0,1,size=(BATCH_SIZE,NOISE_DIM))\n",
        "    ground_truth_y=np.ones((BATCH_SIZE,1))\n",
        "    g_loss=model.train_on_batch(noise,ground_truth_y)\n",
        "    epoch_g_loss+=g_loss\n",
        "\n",
        "  print(\"Epoch %d Disc Loss %.4f generator Loss %.4f\"%((epoch+1),epoch_d_loss/NO_OF_BATCHES,epoch_g_loss/NO_OF_BATCHES))\n",
        "  save_imgs(epoch)\n",
        "  if((epoch+1)%5==0):\n",
        "    generator.save(\"model/gan_generator_{0}.h5\".format(epoch+1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y15-wYDuePOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXpZ82Zi6w_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "122zu-Vr8Bf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
